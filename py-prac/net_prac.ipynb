{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network prac\n",
    "\n",
    "## API, HTTP\n",
    "\n",
    "## HTTP Method: Allows REST api client to manage state of response in web services\n",
    "\n",
    "1. GET - retrieve existing resource\n",
    "2. POST - create new sresponse\n",
    "3. PUT - update existing response\n",
    "4. PATCH - partial update\n",
    "5. DELETE - delete response\n",
    "\n",
    "- after the RESTAPI recieves HTTP req it returns an HTTP res with an HTTP status code\n",
    "- The app that sent the req to the API will perform actions based on the results\n",
    "  - (also include error handling & success messages)\n",
    "    - 2xx - success; 3xx - redirect; 4xx - client error; 5xx - server error\n",
    "- Endpoints: the URLS the RESTAPI exposes that the Client App can use to access a web servers resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datamuse.com/api/ API prac site\n",
    "new_ur = requests.get(\"https://api.datamuse.com/words?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket as sk\n",
    "\n",
    "sock1 = sk.socket(sk.AF_INET, sk.SOCK_STREAM)\n",
    "sock1.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "sock1.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = sock1.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "sock1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network protocol HTTP\n",
    "\n",
    "# socket: make network connections and retrieve data over them\n",
    "\n",
    "## socket connection\n",
    "\n",
    "- socket => connect => send (req) => recv (res)\n",
    "- the program runs the above through port 80 to connect to info from server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. prog init connection to port 80 on the www.py4e.com server\n",
    "2. this prog is the web browser, so HTTP protocol requires sending GET command followed by blank line\n",
    "   1. \\r\\n = EOL (end of line)\n",
    "   2. \\r\\n\\r\\n = nothing between 2 EOL sequences (which is == to a blank line)\n",
    "3. the loop recv the data in 512-chars chunks from socket and prints until recv() returns empty string (there's no more data left to read)\n",
    "\n",
    "### encode() and decode() methods convert strings into bytes objects and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"word\":\"kentucky\",\"score\":129541},{\"word\":\"kentuck\",\"score\":64667}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# par_list = \"words?sp=Kentucky\"\n",
    "f = \"https://api.datamuse.com/words?sp=Kentucky\"\n",
    "# f = \"https://api.datamuse.com/\" + par_list\n",
    "# f = \"https://api.datamuse.com/words?sp=*\"\n",
    "\n",
    "data = requests.get(f)\n",
    "# data = requests.get(f, params= par_list)\n",
    "\n",
    "# print(len(data.text))\n",
    "print(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'kentucky', 'score': 129541}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataText = [{\"word\":\"kentucky\",\"score\":129541},{\"word\":\"kentuck\",\"score\":64667}]\n",
    "dataText2 = {\"one\":{\"word\":\"kentucky\",\"score\":129541},\"two\":{\"word\":\"kentuck\",\"score\":64667}}\n",
    "\n",
    "\n",
    "\n",
    "dataText2.keys()\n",
    "\n",
    "dataText2.get('one')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'Hima', 'Hima', 'b', 'b', 'b', 'b']\n"
     ]
    }
   ],
   "source": [
    "lst = ['a','b','b','b','b']\n",
    "\n",
    "for i in dataText:\n",
    "    lst.insert(1, \"Hima\")\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataText = [{\"word\":\"kentucky\",\"score\":129541},{\"word\":\"kentuck\",\"score\":64667}]\n",
    "\n",
    "lst = []\n",
    "\n",
    "for i in data.text:\n",
    "    lst.insert(0, {\"Hima\":\"kdkkd\"})\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as areq\n",
    "a_u = 'https://github.com/bahim22'\n",
    "# a_u = '\\\\pointpark.edu\\\\files\\\\apps\\\\idphotos\\\\ibalde'\n",
    "data = areq.urlopen(a_u).read()\n",
    "type(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# open and read data from url; only showing output\n",
    "import urllib.request\n",
    "\n",
    "rom_u = 'http://data.pr4e.org/romeo.txt'\n",
    "fh = urllib.request.urlopen(rom_u)\n",
    "for line in fh:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "# retrieve data and compute freq of each word in file\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fha = urllib.request.urlopen(rom_u)\n",
    "\n",
    "counts = dict()\n",
    "for line in fha:\n",
    "    words = line.decode().split()\n",
    "    for w in words:\n",
    "        counts[w] = counts.get(w, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dict method info\n",
    "\n",
    "- dict() -> new empty dictionary dict(mapping) -> new dictionary initialized from a mapping object's (key, value) pairs\n",
    "- dict(iterable) -> new dictionary initialized as if via:\n",
    "  - d = {} for k, v in iterable:\n",
    "  - d[k] = v\n",
    "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
    "    in the keyword argument list. For example: dict(one=1, two=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib\n",
    "\n",
    "- library for opening URLs using a variety of protocols\n",
    "  - The simplest way to use this module is to call the urlopen function, which accepts a string containing a URL or a Request object\n",
    "\n",
    "`urlcleanup`: Clean up temporary files from urlretrieve calls.\n",
    "`urlopen`: Open the URL url, which can be either a string or a Request object.\n",
    "\n",
    ">\n",
    "    - *data* must be an object specifying additional data to be sent to the server, or None if no such data is needed. See Request for details.\n",
    "    - urllib.request module uses HTTP/1.1 and includes a \"Connection:close\" header in its HTTP requests.\n",
    "    - The optional *timeout* parameter specifies a timeout in seconds for blocking operations like the connection attempt (if not specified, the global default timeout setting will be used). This only works for HTTP, HTTPS and FTP connections.\n",
    "    - If *context* is specified, it must be a ssl.SSLContext instance describing the various SSL options. See HTTPSConnection for more details.\n",
    "    - The optional *cafile* and *capath* parameters specify a set of trusted CA certificates for HTTPS requests. cafile should point to a single file containing a bundle of CA certificates, whereas capath should point to a directory of hashed certificate files. More information can be found in ssl.SSLContext.load_verify_locations().\n",
    "    - The *cadefault* parameter is ignored.\n",
    "    - This function always returns an object which can work as a context manager and has the properties url, headers, and status\n",
    "`urlretrieve`\n",
    "\n",
    "> \n",
    "    - Retrieve a URL into a temporary location on disk.\n",
    "    - Requires a URL argument. If a filename is passed, it is used as the temporary file location. The reporthook argument should be a callable that accepts a block number, a read size, and the total file size of the URL target. The data argument should be valid URL encoded data.\n",
    "    - If a filename is passed and the URL points to a local resource, the result is a copy from local file to new file.\n",
    "    - Returns a tuple containing the path to the newly created data file as well as the resulting HTTPMessage object.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do Practice with requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib3 import request\n",
    "\n",
    "\n",
    "# request(method, url, body=None, headers={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the site emails from URL.\"\"\"\n",
    "#Source:https://bit.ly/3o9yYFu\n",
    "__author__ = \"Muhammad Umer Farooq\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0.0\"\n",
    "__maintainer__ = \"Muhammad Umer Farooq\"\n",
    "__email__ = \"contact@muhammadumerfarooq.me\"\n",
    "__status__ = \"Alpha\"\n",
    "\n",
    "import re\n",
    "from html.parser import HTMLParser\n",
    "from urllib import parse\n",
    "\n",
    "import requests\n",
    "class Parser(HTMLParser):\n",
    "    def __init__(self, domain: str):\n",
    "        HTMLParser.__init__(self)\n",
    "        self.data = []\n",
    "        self.domain = domain\n",
    "\n",
    "    def handle_starttag(self, tag: str, attrs: str) -> None:\n",
    "        \"\"\"\n",
    "        This function parse html to take takes url from tags\n",
    "        \"\"\"\n",
    "        # Only parse the 'anchor' tag.\n",
    "        if tag == \"a\":\n",
    "            # Check the list of defined attributes.\n",
    "            for name, value in attrs:\n",
    "                # If href is defined, and not empty nor # print it.\n",
    "                if name == \"href\" and value != \"#\" and value != \"\":\n",
    "                    # If not already in data.\n",
    "                    if value not in self.data:\n",
    "                        url = parse.urljoin(self.domain, value)\n",
    "                        self.data.append(url)\n",
    "\n",
    "\n",
    "# Get main domain name (example.com)\n",
    "def get_domain_name(url: str) -> str:\n",
    "    \"\"\"\n",
    "    This function get the main domain name\n",
    "    >>> get_domain_name(\"https://a.b.c.d/e/f?g=h,i=j#k\")\n",
    "    'c.d'\n",
    "    >>> get_domain_name(\"Not a URL!\")\n",
    "    ''\n",
    "    \"\"\"\n",
    "    return \".\".join(get_sub_domain_name(url).split(\".\")[-2:])\n",
    "# Get sub domain name (sub.example.com)\n",
    "def get_sub_domain_name(url: str) -> str:\n",
    "    \"\"\"\n",
    "    >>> get_sub_domain_name(\"https://a.b.c.d/e/f?g=h,i=j#k\")\n",
    "    'a.b.c.d'\n",
    "    >>> get_sub_domain_name(\"Not a URL!\")\n",
    "    ''\n",
    "    \"\"\"\n",
    "    return parse.urlparse(url).netloc\n",
    "def emails_from_url(url: str = \"https://github.com\") -> list:\n",
    "    \"\"\"\n",
    "    This function takes url and return all valid urls\n",
    "    \"\"\"\n",
    "    # Get the base domain from the url\n",
    "    domain = get_domain_name(url)\n",
    "\n",
    "    # Initialize the parser\n",
    "    parser = Parser(domain)\n",
    "\n",
    "    try:\n",
    "        # Open URL\n",
    "        r = requests.get(url)\n",
    "\n",
    "        # pass the raw HTML to the parser to get links\n",
    "        parser.feed(r.text)\n",
    "\n",
    "        # Get links and loop through\n",
    "        valid_emails = set()\n",
    "        for link in parser.data:\n",
    "            # open URL.\n",
    "            # read = requests.get(link)\n",
    "            try:\n",
    "                read = requests.get(link)\n",
    "                # Get the valid email.\n",
    "                emails = re.findall(\"[a-zA-Z0-9]+@\" + domain, read.text)\n",
    "                # If not in list then append it.\n",
    "                for email in emails:\n",
    "                    valid_emails.add(email)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    except ValueError:\n",
    "        exit(-1)\n",
    "\n",
    "    # Finally return a sorted list of email addresses with no duplicates.\n",
    "    return sorted(valid_emails)\n",
    "if __name__ == \"__main__\":\n",
    "    emails = emails_from_url(\"https://github.com\")\n",
    "    print(f\"{len(emails)} emails found:\")\n",
    "    print(\"\\n\".join(sorted(emails)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://bit.ly/2MjeQ6z\n",
    "import requests\n",
    "APPID = \"**************************\"  # <-- Put your OpenWeatherMap appid here!\n",
    "URL_BASE = \"http://api.openweathermap.org/data/2.5/\"\n",
    "def current_weather(q: str = \"\", appid: str = APPID) -> dict:\n",
    "    \"\"\"https://openweathermap.org/api\"\"\"\n",
    "    return requests.get(URL_BASE + \"weather\", params=locals()).json()\n",
    "def weather_forecast(q: str = \"\", appid: str = APPID) -> dict:\n",
    "    \"\"\"https://openweathermap.org/forecast5\"\"\"\n",
    "    return requests.get(URL_BASE + \"forecast\", params=locals()).json()\n",
    "def weather_onecall(lat: float = 55.68, lon: float = 12.57, appid: str = APPID) -> dict:\n",
    "    \"\"\"https://openweathermap.org/api/one-call-api\"\"\"\n",
    "    return requests.get(URL_BASE + \"onecall\", params=locals()).json()\n",
    "if __name__ == \"__main__\":\n",
    "    from pprint import pprint\n",
    "    while True:\n",
    "        location = input(\"Input a location: \").strip()\n",
    "        if location:\n",
    "            pprint(current_weather(location))\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# set up authentication info\n",
    "authinfo = urllib.request.HTTPBasicAuthHandler() \n",
    "\n",
    "authinfo.add_password(realm=\"PDQ Application\",\n",
    "uri='https://mahler:8092/site-updates.py', user='klem', passwd='geheim$parole')\n",
    "\n",
    "proxy_support = urllib.request.ProxyHandler({\"http\" : \"http://ahad-haam:3128\"})\n",
    "\n",
    "# build a new opener that adds authentication and caching FTP handlers\n",
    "opener = urllib.request.build_opener(proxy_support, authinfo, urllib.request.CacheFTPHandler)\n",
    "\n",
    "# install it\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "f = urllib.request.urlopen('https://www.python.org/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# par_list = \n",
    "api_url = \"https//:api.datamuse.com/words?\"\n",
    "\n",
    "f = open(\"../Docs/PyDocs22.md\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://www.pointpark.edu/index')\n",
    "\n",
    "print(\"Response text of res: \")\n",
    "print(res.text)\n",
    "print(\"\\n===================\")\n",
    "print(\"\\nContent of the url: \")\n",
    "print(\"\\n===================\")\n",
    "print(\"\\nRaw data of url\")\n",
    "\n",
    "r = requests.get(\"https://api.github.com/events\", stream = True)\n",
    "print(r.raw)\n",
    "print(r.raw.read(10))\n",
    "# print(res.next)\n",
    "# print(res.raise_for_status)\n",
    "# print(res.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. res.text = Content of the response, in unicode.\n",
    "2. res.content = Content of the response, in bytes.\n",
    "3. iter_content: Iterates over the response data. When stream=True is set on the request, this avoids reading the content at once into memory for large responses. The chunk size is the number of bytes it should read into memory.\n",
    "   1. iter_lines: Iterates over the response data, one line at a time. \n",
    "4. status_code, headers, json, \n",
    "5. __non-zero__ | = This attribute checks if the status code of the response is between 400 and 600 to see if there was a client error or a server error.\n",
    "6. .ok Returns True if status_code is less than 400, False if not.\n",
    "7. res.next: Returns a PreparedRequest for the next request in a redirect chain, if there is one.\n",
    "8. raise_for_status: returns HTTP error if one occurred\n",
    "\n",
    "```py\n",
    "if HTTP error:\n",
    "    return res.status_code\n",
    "    Print(res.status_code, error)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests: python HTTP Library example\n",
    "\n",
    "## GET usage:\n",
    "\n",
    "```py\n",
    ">>> import requests\n",
    ">>> r = requests.get('https://www.python.org')\n",
    ">>> r.status_code\n",
    "200\n",
    ">>> b'Python is a programming language' in r.content\n",
    "True\n",
    "... or POST:\n",
    "\n",
    ">>> payload = dict(key1='value1', key2='value2')\n",
    ">>> r = requests.post('https://httpbin.org/post', data=payload)\n",
    ">>> print(r.text)\n",
    "{\n",
    "  ...\n",
    "  \"form\": {\n",
    "    \"key1\": \"value1\",\n",
    "    \"key2\": \"value2\"\n",
    "  },\n",
    "  ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files3 = 'file://pointpark.edu/files/Users/Facstaff/ibalde'\n",
    "\n",
    "'hasn\\'t'\n",
    "\"hasn't\"\n",
    "print('''\\\n",
    "    Topic: Python\n",
    "    Date: Oct. 06\n",
    "''')\n",
    "print(r'C:\\some\\name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'data.pr4e.org'\n",
    "\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((HOST, PORT))\n",
    "mysock.sendall(b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "mysock.sendall(b'GET file://pointpark.edu/files/Apps/IDPhotos/ibalde14623.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if len(data) < 1: break\n",
    "    # flow control\n",
    "    # buffer between server making send() req & app recv() req\n",
    "    # after filling up buffer this makes server wait for app to empty buffer \n",
    "    time.sleep(0.25) \n",
    "    count = count + len(data)\n",
    "    print(len(data), count)\n",
    "    picture = picture + data\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Look for end of header (2 CRLF)\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print('Header length', pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# skip header and save pic data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def store_in_mongodb(self, news):\n",
    "        \"\"\"\n",
    "        - init MongoDB cluster https://www.mongodb.com/cloud/atlas/register\n",
    "        - Connect to the MongoDB cluster\n",
    "        - Create a new collection\n",
    "        - Insert the news into the collection\n",
    "         :param news: the news object that we created in the previous function\n",
    "        \"\"\"\n",
    "\n",
    "        load_dotenv()\n",
    "\n",
    "        db_user = os.getenv(\"DB_USER\")\n",
    "        db_pw = os.getenv(\"DB_PW\")\n",
    "        db_name = os.getenv(\"DB_NAME\")\n",
    "        collection_name = os.getenv(\"COLLECTION_NAME\")\n",
    "\n",
    "        collection = connect_database(db_user, db_pw, db_name, collection_name)\n",
    "        post_database(collection, news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from urllib import request\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def main():\n",
    "\n",
    "    model_name, dataset_name = getRuntimeArgs()\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    run = Run.get_context()\n",
    "\n",
    "    if run._run_id.startswith(\"_OfflineRun\"):\n",
    "        run = None\n",
    "\n",
    "    credit_data_df = None\n",
    "\n",
    "    #Load data from Dataset or from local file(for offline runs)\n",
    "    if run is None:\n",
    "        dataset_filename = os.environ.get(\"DATASET_FILE_NAME\", )\n",
    "        credit_data_df = pd.read_csv(\"dataset/\" +dataset_filename)\n",
    "    else:\n",
    "        dataset = Dataset.get_by_name(workspace=run.experiment.workspace, name=dataset_name)\n",
    "        #dataset = run.input_datasets[dataset_name]\n",
    "        credit_data_df = dataset.to_pandas_dataframe()\n",
    "\n",
    "    clf = model_train(credit_data_df, run)\n",
    "\n",
    "    #copying to \"outputs\" directory, automatically uploads it to azure ml\n",
    "    output_dir = './outputs/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    joblib.dump(value=clf, filename=output_dir+model_name)\n",
    "\n",
    "    #run.upload_file(name=\"./outputs/\" + model_file_name, path_or_stream=model_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "\n",
    "def get_city_weather(city_name):\n",
    "    \"\"\"\n",
    "    Uses Open Weather Map API to fetch Current Weather Details of a Given City\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    # Not Setting Up API Key will respond with a 401 Error Code and Invalid\n",
    "    # API Key message\n",
    "    OPEN_WEATHER_API_KEY = os.getenv(\"OPEN_WEATHER_API_KEY\")\n",
    "    URL = (\n",
    "        f'http://api.openweathermap.org/data/2.5/weather?'\n",
    "        f'q={city_name}&appid={OPEN_WEATHER_API_KEY}'\n",
    "    )\n",
    "    response = request.get(URL).json()\n",
    "    return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bbfbb50d7f9d1744171a66d1182335b07328b0cb7bc3f83512aab5e969c6d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
